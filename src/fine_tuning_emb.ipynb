{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load data from vectorstore and create QA dataset",
   "id": "2a5e699746f42ed5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from src.data_loaders.document_processor import DocumentProcessor\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "document_processor = DocumentProcessor('au-blog-rag', dimension=1536)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# documents = [document['content'] for document in document_processor.get_all_documents()]\n",
    "documents = document_processor.get_all_documents()"
   ],
   "id": "90c7bffaa2fb2d64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import Document\n",
    "import random\n",
    "\n",
    "\n",
    "def load_corpus_from_string(custom_docs: list[dict], verbose=False):\n",
    "    # Create a Document objects from the content and metadata\n",
    "    docs = []\n",
    "    for custom_doc in custom_docs:\n",
    "        docs.append(Document(text=custom_doc['content'], metadata=custom_doc['metadata']))\n",
    "\n",
    "    # Use SentenceSplitter to split the content into nodes\n",
    "    parser = SentenceSplitter()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Parsed {len(nodes)} nodes\")\n",
    "\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def split_documents(docs: list[dict], val_ratio=0.2):\n",
    "    \"\"\"Split a list of documents into training and validation sets.\"\"\"\n",
    "    random.shuffle(docs)\n",
    "    split_index = int(len(docs) * (1 - val_ratio))\n",
    "    train_docs = docs[:split_index]\n",
    "    val_docs = docs[split_index:]\n",
    "    return train_docs, val_docs\n",
    "\n",
    "documents_train, documents_val = split_documents(documents, val_ratio=0.2)\n",
    "\n",
    "train_nodes = load_corpus_from_string(documents_train)\n",
    "val_nodes = load_corpus_from_string(documents_val)\n",
    "print(len(train_nodes), len(val_nodes))"
   ],
   "id": "d7ffea07b1919c2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "train_dataset = generate_qa_embedding_pairs(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    nodes=train_nodes,\n",
    "    output_path=\"train_dataset.json\",\n",
    ")\n",
    "val_dataset = generate_qa_embedding_pairs(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    nodes=val_nodes,\n",
    "    output_path=\"val_dataset.json\",\n",
    ")"
   ],
   "id": "88339059b992ff1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load QA data from .json and fine-tune all-MiniLM-L6-v2",
   "id": "a86d555feab8de84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:14:33.018826Z",
     "start_time": "2025-01-10T10:14:32.082316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "\n",
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
   ],
   "id": "7cbeb827a75ff430",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:14:37.761881Z",
     "start_time": "2025-01-10T10:14:34.254960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "\n",
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    train_dataset,\n",
    "    model_id=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_output_path=\"fine-tuned-model\",\n",
    "    val_dataset=val_dataset,\n",
    "    epochs=1,\n",
    ")"
   ],
   "id": "885a8de66ff20979",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.5.1 available.\n",
      "PyTorch version 2.5.1 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "finetune_engine.finetune()",
   "id": "118f6d424e3031",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:14:52.778267Z",
     "start_time": "2025-01-10T10:14:52.236096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_model = finetune_engine.get_finetuned_model()\n",
    "embed_model"
   ],
   "id": "177263b0477f14f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: fine-tuned-model\n",
      "Load pretrained SentenceTransformer: fine-tuned-model\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbedding(model_name='fine-tuned-model', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7f4c202dc390>, num_workers=None, max_length=256, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate models",
   "id": "1bbf72a587eb2e81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:36:53.355857Z",
     "start_time": "2025-01-10T10:36:52.424776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "\n",
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
   ],
   "id": "e906b0386b7aa4d7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:36:53.380227Z",
     "start_time": "2025-01-10T10:36:53.358133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.schema import TextNode\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    dataset,\n",
    "    embed_model,\n",
    "    top_k=5,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "    \n",
    "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
    "    index = VectorStoreIndex(nodes, embed_model=embed_model, show_progress=True)\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "        is_hit = expected_id in retrieved_ids\n",
    "    \n",
    "        eval_result = {\n",
    "            \"is_hit\": is_hit,\n",
    "            \"retrieved\": retrieved_ids,\n",
    "            \"expected\": expected_id,\n",
    "            \"query\": query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results"
   ],
   "id": "1d80fe5e224e9f69",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:39:31.146731Z",
     "start_time": "2025-01-10T10:36:53.452766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "embedding_openai = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "openai_res = evaluate(val_dataset, embedding_openai)"
   ],
   "id": "ff71dac057df0e15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/209 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caf393d99c394b64ace3037fc249eb39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/418 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff0396b5eb084296a08934c36e3dc2ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:39:36.625824Z",
     "start_time": "2025-01-10T10:39:31.159620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# fine_tuned = \"local:fine-tuned-model\"\n",
    "fine_tuned = HuggingFaceEmbeddings(model_name=\"wylupek/au-blog-rag-embedder\")\n",
    "fine_tuned_res = evaluate(val_dataset, fine_tuned)"
   ],
   "id": "d7d3b3261e2a9c9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/209 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94b4047bb35b443ea7310bd10866b8e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/418 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5716b6ddf594b258f79a983d1c575c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:39:40.210411Z",
     "start_time": "2025-01-10T10:39:36.637426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "original_res = evaluate(val_dataset, original)"
   ],
   "id": "1138345412c634db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/209 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad6fc7cc99f64758bdeaa85ab54aa76b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/418 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82ceaa256e2c43b68714a26c5f2904fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:39:40.223806Z",
     "start_time": "2025-01-10T10:39:40.220702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_openai = pd.DataFrame(openai_res)\n",
    "hit_rate_openai = df_openai[\"is_hit\"].mean()\n",
    "\n",
    "df_ft = pd.DataFrame(fine_tuned_res)\n",
    "hit_rate_ft = df_ft[\"is_hit\"].mean()\n",
    "\n",
    "df_og = pd.DataFrame(original_res)\n",
    "hit_rate_og = df_og[\"is_hit\"].mean()\n",
    "\n",
    "print(\n",
    "    f\"text-embedding-3-small:\\t\\t{hit_rate_openai}\\n\"\n",
    "    f\"all-MiniLM-L6-v2:\\t\\t\\t{hit_rate_og}\\n\"\n",
    "    f\"all-MiniLM-L6-v2-fine-tuned:\\t{hit_rate_ft}\"\n",
    ")"
   ],
   "id": "e21a1a99452fe61f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-embedding-3-small:\t\t0.9282296650717703\n",
      "all-MiniLM-L6-v2:\t\t\t0.8947368421052632\n",
      "all-MiniLM-L6-v2-fine-tuned:\t0.9593301435406698\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
